{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osavelyev/sber/blob/main/Main%20-%20regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdcibR-RRk6b"
      },
      "source": [
        " # **Тема занятия:** Линейная регрессия, классификация на примере логистической регрессии, SVM и KNN\n",
        "\n",
        " Занятие состоит из следующих частей:\n",
        "\n",
        " - [**Презентация.**](https://drive.google.com/file/d/1je-YG-SU7dV-xmZSUF-yqB7qjYWOWhQu/view?usp=sharing) Краткий обзор классических ML алгоритмов: KNN, Линейная регрессия, логистическая регрессия, SVM.\n",
        "\n",
        "\n",
        " - [**Обучающий ноутбук №1**]( https://colab.research.google.com/drive/1au2UdCsZKCHwYEKvdH95AQig_g4B9izr). Аналитическое решение линейной регрессии.\n",
        "\n",
        " - [**Обучающий ноутбук №2**](https://colab.research.google.com/drive/1aqRvKK0WRq8hn89bm1O__khM5cg1wuW7). Решение линейной регрессии при помощи градиентного спуска.\n",
        "\n",
        " - [**Обучающий ноутбук №3**](https://colab.research.google.com/drive/14niD6w38EU_6oc-4rSaePRkHNkKlBur7). Классификация, метрики для классификации. Регрессия, метрики для регрессии. Работа с признаками. Использование готовых библиотек для реализации алгоритма."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlDEKrwNbu8"
      },
      "source": [
        "# Рекомендованная литература\n",
        "\n",
        "- [Матричные производные](http://www.machinelearning.ru/wiki/images/archive/9/93/20170127140036!MO17_seminar3.pdf)\n",
        "- [Решение уравнения простой линейной регрессии](https://habr.com/ru/post/474602/)\n",
        "\n",
        "- [Линейные модели классификации и регрессии](https://habr.com/ru/company/ods/blog/323890/)\n",
        "\n",
        "- [Линейная регрессия в подробностях](https://habr.com/ru/company/ods/blog/322076/)\n",
        "\n",
        "- [Функция ошибок в задачах регрессии](https://alexanderdyakonov.files.wordpress.com/2018/10/book_08_metrics_12_blog1.pdf)\n",
        "\n",
        "- Градиентный спуск:\n",
        "    - [Часть 1](https://habr.com/ru/post/307312/)\n",
        "    - [Часть 2](https://habr.com/ru/post/308604/)\n",
        "\n",
        "- [Про смещение (bias) и разброс (variance) ML алгоритма](https://dyakonov.org/2018/04/25/смещение-bias-и-разброс-variance-модели-алгорит/)\n",
        "\n",
        "- [О метриках качества в машинном обучении](https://habr.com/ru/company/ods/blog/328372/)\n",
        "\n",
        "- [Кривые в машинном обучении (ROC-кривая, precision-recall кривая и тд);\n",
        "](https://dyakonov.org/2019/08/29/кривые-в-машинном-обучении/)\n",
        "    - [Подробнее про ROC-AUC кривую](https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/)\n",
        "\n",
        "- [Применение решения задачи: \"Определение вероятности невозврата кредита\"](https://dyakonov.org/2017/12/25/определение-вероятности-невозврата/)"
      ]
    }
  ]
}